{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on MNIST with XABY\n",
    "\n",
    "This notebook demonstrates how to train a fully connected network (not convolutional!) on MNIST with the XABY framework. I'll also compare it to PyTorch so you can see the different APIs and performances.\n",
    "\n",
    "I'm going to use torchvision to load in the MNIST data, because it's super great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import xaby\n",
    "import xaby.nn.functional as xf\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(\"~/.pytorch\", train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(\"~/.pytorch\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=128, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Models\n",
    "\n",
    "First up, I'll define two models with the same architecture. One with XABY, the other with PyTorch. \n",
    "\n",
    "XABY models are defined as a sequence of operations. When a model is defined, it is compiled behind the scenes into a single function. You call the function with some input like `inputs >> model`. I had a lot of fun messing with Python operators. My intention of doing it this way is if you chain a lot of functions, the last function called is the first function you read. I'm using the `>>` operator so you can write the chain of functions in the order they are called.\n",
    "\n",
    "You can define the PyTorch model with `torch.nn.Sequential`, but sublassing from `torch.nn.Module` is the preferred method, so I'll do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## XABY model ##\n",
    "xaby_model = xf.flatten >> xf.linear(784, 256) >> xf.relu >> xf.linear(256, 10) >> xf.log_softmax\n",
    "\n",
    "## PyTorch Model ##\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "torch_model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run data through the models!\n",
    "\n",
    "Just a small example of using XABY models for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XABY device: GPU_0\n"
     ]
    }
   ],
   "source": [
    "# Get data from the image loader\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "# Convert PyTorch Tensor to a XABY Tensor\n",
    "inputs = xaby.Tensor(images)\n",
    "\n",
    "# Thanks to JAX, XABY tensors are automatically on the GPU\n",
    "print(f\"XABY device: {inputs.device()}\")\n",
    "\n",
    "# Call the model in a fun manner\n",
    "log_p = inputs >> xaby_model\n",
    "\n",
    "# Normal function call... boring....\n",
    "log_p = xaby_model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should also note you can run XABY tensors through operations without creating models. This returns another Tensor. If you start the sequence with an operation, it'll create a model. If you start with a tensor, it'll run through the operations and return a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor([[ -0.3852086  -10.208656    -4.454486   ...  -2.8513358   -5.7166343\n",
       "   -7.173292  ]\n",
       " [ -0.16765976  -5.399795    -5.7430463  ...  -3.962609    -6.4383087\n",
       "   -6.3500037 ]\n",
       " [ -5.0375943   -5.699171   -10.508496   ...  -4.827385    -5.69089\n",
       "   -6.901062  ]\n",
       " ...\n",
       " [ -3.5123837   -4.5302687   -6.137228   ...  -5.2335353   -1.0158901\n",
       "   -9.262663  ]\n",
       " [ -0.6661906   -9.394583    -2.7893095  ...  -5.8804502   -5.424393\n",
       "   -3.649283  ]\n",
       " [ -3.7532034  -12.018103   -11.665488   ...  -7.9599133  -14.067234\n",
       "  -14.053231  ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs >> xf.flatten >> xf.linear(784, 10) >> xf.log_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing XABY and PyTorch\n",
    "\n",
    "Below I'll test how long it takes for inference with these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 µs ± 11.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# First on CPU\n",
    "torch_model = torch_model.requires_grad_(False)\n",
    "torch_model.to(\"cpu\")\n",
    "images = images.to(\"cpu\")\n",
    "\n",
    "%timeit -n 1000 torch_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 µs ± 460 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Now on GPU\n",
    "torch_model.to(\"cuda\")\n",
    "images = images.to(\"cuda\")\n",
    "\n",
    "%timeit -n 1000 torch_model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 µs ± 5.18 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# Now the XABY model, runs on GPU!\n",
    "inputs = xaby.Tensor(images.to(\"cpu\"))\n",
    "\n",
    "%timeit -n 1000 inputs >> xaby_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XABY is slightly slower than PyTorch on the GPU. This might be due to JAX being slower or it's possible I can do some more optimization in XABY.\n",
    "\n",
    "Either way, time to train the models. First up, XABY. I'll use simple stochastic gradient descent for both. The output of the models is log-softmax, so I'll use the negative log-likelihood loss.\n",
    "\n",
    "In XABY, we create a `backprop` object that takes the input and targets, then returns the loss and gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = train_loader.batch_size\n",
    "print_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.208  Test loss: 1.276  Test accuracy: 0.590  Images/sec: 5919.404\n",
      "Train loss: 0.903  Test loss: 0.852  Test accuracy: 0.727  Images/sec: 14378.808\n",
      "Train loss: 0.760  Test loss: 0.695  Test accuracy: 0.781  Images/sec: 14424.387\n",
      "Train loss: 0.599  Test loss: 0.605  Test accuracy: 0.810  Images/sec: 14358.304\n"
     ]
    }
   ],
   "source": [
    "# Define a fresh model\n",
    "model = xf.flatten >> xf.linear(784, 256) >> xf.relu >> xf.linear(256, 10) >> xf.log_softmax\n",
    "\n",
    "# Backprogate the loss through the model\n",
    "backprop = model << xaby.losses.nlloss\n",
    "\n",
    "# Create the optimizer\n",
    "optimize = xaby.optim.SGD(model, lr=0.003)\n",
    "\n",
    "step = 0\n",
    "start = time.time()\n",
    "for images, labels in train_loader:\n",
    "    step += 1\n",
    "    \n",
    "    inputs, targets = xaby.Tensor(images), xaby.Tensor(labels)\n",
    "    \n",
    "    # Backprop to get gradients!\n",
    "    train_loss, grads = inputs >> backprop << targets\n",
    "    # Update model parameters with gradients\n",
    "    optimize(grads)\n",
    "    \n",
    "    if step % print_every == 0:\n",
    "        stop = time.time()\n",
    "        test_losses = []\n",
    "        test_accuracy = []\n",
    "        for images, labels in test_loader:\n",
    "            inputs, targets = xaby.Tensor(images), xaby.Tensor(labels)\n",
    "            log_p = inputs >> model\n",
    "            loss = log_p >> xaby.losses.nlloss << targets\n",
    "            accuracy = xaby.metrics.accuracy(log_p, targets)\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "            test_accuracy.append(accuracy.item())\n",
    "            \n",
    "        print(f\"Train loss: {train_loss.item():.3f}  \"\n",
    "              f\"Test loss: {sum(test_losses)/len(test_losses):.3f}  \"\n",
    "              f\"Test accuracy: {sum(test_accuracy)/len(test_accuracy):.3f}  \"\n",
    "              f\"Images/sec: {print_every*batch_size/(stop - start):.3f}\")\n",
    "        start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.786  Test loss: 1.790  Test accuracy: 0.632  Images/sec: 13148.382\n",
      "Train loss: 1.348  Test loss: 1.331  Test accuracy: 0.759  Images/sec: 14306.074\n",
      "Train loss: 1.029  Test loss: 1.018  Test accuracy: 0.805  Images/sec: 14353.490\n",
      "Train loss: 0.874  Test loss: 0.828  Test accuracy: 0.832  Images/sec: 14343.788\n"
     ]
    }
   ],
   "source": [
    "# Start with a fresh model\n",
    "torch_model = torch.nn.Sequential(\n",
    "                    torch.nn.Flatten(),\n",
    "                    torch.nn.Linear(784, 256),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Linear(256, 10),\n",
    "                    torch.nn.LogSoftmax(1))\n",
    "torch_model.to(\"cuda\")\n",
    "optimizer = torch.optim.SGD(torch_model.parameters(), lr=0.003)\n",
    "criterion = torch.nn.NLLLoss()\n",
    "\n",
    "step = 0\n",
    "start = time.time()\n",
    "for images, labels in train_loader:\n",
    "    step += 1\n",
    "    \n",
    "    inputs, targets = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    log_p = torch_model(inputs)\n",
    "    loss = criterion(log_p, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_loss = loss.item()\n",
    "    \n",
    "    if step % print_every == 0:\n",
    "        stop = time.time()\n",
    "        test_losses = []\n",
    "        test_accuracy = []\n",
    "        for images, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                inputs, targets = images.to(\"cuda\"), labels.to(\"cuda\")\n",
    "                log_p = torch_model(inputs)\n",
    "                loss = criterion(log_p, targets)\n",
    "                accuracy = (log_p.argmax(axis=1) == targets).sum()/float(len(images))\n",
    "            \n",
    "            test_losses.append(loss.item())\n",
    "            test_accuracy.append(accuracy.item())\n",
    "            \n",
    "        print(f\"Train loss: {train_loss:.3f}  \"\n",
    "              f\"Test loss: {sum(test_losses)/len(test_losses):.3f}  \"\n",
    "              f\"Test accuracy: {sum(test_accuracy)/len(test_accuracy):.3f}  \"\n",
    "              f\"Images/sec: {print_every*batch_size/(stop - start):.3f}\")\n",
    "        start = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
